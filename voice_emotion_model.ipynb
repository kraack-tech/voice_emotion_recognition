{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff11bd84-af4e-4acd-ab59-f7886776ec1c",
   "metadata": {},
   "source": [
    "# Voice Emotion Recognition: Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150db6fa-dd11-40d9-9317-c8743978eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8da6c5-3648-4852-9476-08fc8135ae26",
   "metadata": {},
   "source": [
    "#### Import audio feature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078dafb0-c796-4b07-bf6a-a626832b99f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2675</th>\n",
       "      <th>2676</th>\n",
       "      <th>2677</th>\n",
       "      <th>2678</th>\n",
       "      <th>2679</th>\n",
       "      <th>2680</th>\n",
       "      <th>2681</th>\n",
       "      <th>2682</th>\n",
       "      <th>2683</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.092285</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>0.049805</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.054199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129883</td>\n",
       "      <td>0.161621</td>\n",
       "      <td>0.187012</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.092773</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.057617</td>\n",
       "      <td>0.061523</td>\n",
       "      <td>0.084961</td>\n",
       "      <td>0.147949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.092285</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>0.049805</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.054199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083984</td>\n",
       "      <td>0.117676</td>\n",
       "      <td>0.141113</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.051758</td>\n",
       "      <td>0.045898</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.061035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061035</td>\n",
       "      <td>0.092285</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>0.103516</td>\n",
       "      <td>0.084961</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.035645</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235471</th>\n",
       "      <td>0.083984</td>\n",
       "      <td>0.133789</td>\n",
       "      <td>0.161133</td>\n",
       "      <td>0.153320</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.086426</td>\n",
       "      <td>0.095215</td>\n",
       "      <td>0.108398</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.996235</td>\n",
       "      <td>-4.265385</td>\n",
       "      <td>-1.865951</td>\n",
       "      <td>-2.166432</td>\n",
       "      <td>-17.060484</td>\n",
       "      <td>-9.683095</td>\n",
       "      <td>-0.542660</td>\n",
       "      <td>-0.719571</td>\n",
       "      <td>-6.080200</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235472</th>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.099609</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>0.052734</td>\n",
       "      <td>0.036621</td>\n",
       "      <td>0.032715</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.155140</td>\n",
       "      <td>-3.369991</td>\n",
       "      <td>-1.089657</td>\n",
       "      <td>0.174891</td>\n",
       "      <td>-19.147015</td>\n",
       "      <td>-12.684088</td>\n",
       "      <td>0.123865</td>\n",
       "      <td>-1.245382</td>\n",
       "      <td>-5.587992</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235473</th>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.176758</td>\n",
       "      <td>0.139648</td>\n",
       "      <td>0.121094</td>\n",
       "      <td>0.112793</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.153809</td>\n",
       "      <td>0.174805</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.238156</td>\n",
       "      <td>-2.266622</td>\n",
       "      <td>0.860346</td>\n",
       "      <td>-1.415168</td>\n",
       "      <td>-17.360427</td>\n",
       "      <td>-9.504957</td>\n",
       "      <td>0.042696</td>\n",
       "      <td>-0.656188</td>\n",
       "      <td>-5.901685</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235474</th>\n",
       "      <td>0.045898</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.094727</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.051758</td>\n",
       "      <td>0.035645</td>\n",
       "      <td>0.032715</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.817496</td>\n",
       "      <td>-7.855257</td>\n",
       "      <td>-4.327174</td>\n",
       "      <td>-6.591506</td>\n",
       "      <td>-18.465111</td>\n",
       "      <td>-14.346745</td>\n",
       "      <td>0.730882</td>\n",
       "      <td>-8.990791</td>\n",
       "      <td>-5.316560</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235475</th>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.116699</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>0.076660</td>\n",
       "      <td>0.082520</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.012169</td>\n",
       "      <td>0.884069</td>\n",
       "      <td>2.511671</td>\n",
       "      <td>0.486484</td>\n",
       "      <td>-17.122528</td>\n",
       "      <td>-15.097058</td>\n",
       "      <td>-1.169470</td>\n",
       "      <td>-0.801278</td>\n",
       "      <td>-4.412979</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235476 rows × 2685 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0       0.058594  0.092285  0.115723  0.106445  0.087891  0.066406  0.049805   \n",
       "1       0.129883  0.161621  0.187012  0.113281  0.092773  0.073242  0.057617   \n",
       "2       0.058594  0.092285  0.115723  0.106445  0.087891  0.066406  0.049805   \n",
       "3       0.083984  0.117676  0.141113  0.109375  0.089844  0.068359  0.051758   \n",
       "4       0.061035  0.092285  0.115723  0.103516  0.084961  0.063965  0.048340   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "235471  0.083984  0.133789  0.161133  0.153320  0.117188  0.093750  0.086426   \n",
       "235472  0.046875  0.078125  0.099609  0.097656  0.076172  0.052734  0.036621   \n",
       "235473  0.085938  0.145508  0.187500  0.176758  0.139648  0.121094  0.112793   \n",
       "235474  0.045898  0.076172  0.097656  0.094727  0.074219  0.051758  0.035645   \n",
       "235475  0.054688  0.097656  0.116699  0.111816  0.091797  0.076660  0.082520   \n",
       "\n",
       "               7         8         9  ...       2675      2676      2677  \\\n",
       "0       0.043945  0.038086  0.054199  ...   0.000000  0.000000  0.000000   \n",
       "1       0.061523  0.084961  0.147949  ...   0.000000  0.000000  0.000000   \n",
       "2       0.043945  0.038086  0.054199  ...   0.000000  0.000000  0.000000   \n",
       "3       0.045898  0.041016  0.061035  ...   0.000000  0.000000  0.000000   \n",
       "4       0.041992  0.035645  0.050781  ...   0.000000  0.000000  0.000000   \n",
       "...          ...       ...       ...  ...        ...       ...       ...   \n",
       "235471  0.095215  0.108398  0.132812  ... -11.996235 -4.265385 -1.865951   \n",
       "235472  0.032715  0.029297  0.035156  ... -11.155140 -3.369991 -1.089657   \n",
       "235473  0.130859  0.153809  0.174805  ... -12.238156 -2.266622  0.860346   \n",
       "235474  0.032715  0.029297  0.034180  ...  -4.817496 -7.855257 -4.327174   \n",
       "235475  0.117188  0.156250  0.183594  ...  -3.012169  0.884069  2.511671   \n",
       "\n",
       "            2678       2679       2680      2681      2682      2683  Emotion  \n",
       "0       0.000000   0.000000   0.000000  0.000000  0.000000  0.000000    angry  \n",
       "1       0.000000   0.000000   0.000000  0.000000  0.000000  0.000000    angry  \n",
       "2       0.000000   0.000000   0.000000  0.000000  0.000000  0.000000    angry  \n",
       "3       0.000000   0.000000   0.000000  0.000000  0.000000  0.000000    angry  \n",
       "4       0.000000   0.000000   0.000000  0.000000  0.000000  0.000000    angry  \n",
       "...          ...        ...        ...       ...       ...       ...      ...  \n",
       "235471 -2.166432 -17.060484  -9.683095 -0.542660 -0.719571 -6.080200    happy  \n",
       "235472  0.174891 -19.147015 -12.684088  0.123865 -1.245382 -5.587992    happy  \n",
       "235473 -1.415168 -17.360427  -9.504957  0.042696 -0.656188 -5.901685    happy  \n",
       "235474 -6.591506 -18.465111 -14.346745  0.730882 -8.990791 -5.316560    happy  \n",
       "235475  0.486484 -17.122528 -15.097058 -1.169470 -0.801278 -4.412979    happy  \n",
       "\n",
       "[235476 rows x 2685 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the extracted audio features from 'feature_extraction.ipynb' notebook\n",
    "# The file is approx. 9.4 GB, so it might take a while to load \n",
    "feature_df = pd.read_csv('./extracted_features.csv')\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c511982-09ce-4ff9-b19c-431f68866e7b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94cb43c0-e809-44c5-b120-94bb1a81e361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "X_train: (188380, 2684, 1), y_train: (188380, 7)\n",
      "Test shape:\n",
      "X_test: (47096, 2684, 1), y_test: (47096, 7)\n"
     ]
    }
   ],
   "source": [
    "# Define extracted audio features (X) and emotion labels (Y)\n",
    "features = feature_df.iloc[:, :-1].values  # All comlumns feature columns\n",
    "labels = OneHotEncoder(sparse_output=False).fit_transform(feature_df[['Emotion']]) # One-hot encode emotions labels and reshape\n",
    "\n",
    "# Split data into training and test sets (80/20%)\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Scale the data using StandardScaler and reshape \n",
    "scaler = StandardScaler()\n",
    "X_train = np.expand_dims(scaler.fit_transform(x_train), axis=-1) # Training data\n",
    "X_test = np.expand_dims(scaler.transform(x_test), axis=-1) # Test data\n",
    "\n",
    "# Print shapes of training and test data\n",
    "print(f\"Training shape:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Test shape:\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533544d9-5da3-4732-b01d-7ef3a72a6470",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89445494-d1b9-48ad-9782-dfa2d41b31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# First convolutional block with 512 filters and kernel size of 5\n",
    "model.add(layers.Conv1D(512, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "\n",
    "# Second convolutional block with 512 filters and kernel size of 5\n",
    "model.add(layers.Conv1D(512, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(layers.Dropout(0.20))  # Early dropout with 20% probability\n",
    "\n",
    "# Third convolutional block with 512 filters and kernel size of 5\n",
    "model.add(layers.Conv1D(512, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size=3, strides=2, padding='same'))\n",
    "\n",
    "# Fourth convolutional block with 256 filters and kernel size of 5\n",
    "model.add(layers.Conv1D(256, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size=3, strides=2, padding='same'))\n",
    "model.add(layers.Dropout(0.15)) # Reduced dropout with 15% probability\n",
    "\n",
    "# Fifth convolutional block with 256 filters and kernel size of 3\n",
    "model.add(layers.Conv1D(256, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(layers.Dropout(0.15)) \n",
    "\n",
    "# Sixth convolutional block with 128 filters and kernel size of 3\n",
    "model.add(layers.Conv1D(128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(layers.Dropout(0.15))\n",
    "\n",
    "# Seventh convolutional block with 128 filters and kernel size of 3\n",
    "model.add(layers.Conv1D(128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(layers.Dropout(0.15))\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(layers.Flatten()) # Flatten to prepare\n",
    "model.add(layers.Dense(512, activation='relu'))  # Dense layer with 512 units\n",
    "model.add(layers.BatchNormalization())  # Batch normalization \n",
    "\n",
    "# Output layer with the 7 emotion classes, using softmax activation for the multi-class classification\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model using adam and categorical crossentropy loss\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f365ddb-7ede-42ee-ab7e-ad93bfe73fc1",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff6f07f9-cb22-4293-b305-a2618f7c1445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Class Weights: {0: 0.8566699105949122, 1: 2.536421166015888, 2: 2.551088119388432, 3: 0.7873443116275182, 4: 0.5727054388471712, 5: 0.9226670062546224, 6: 1.0565931908688093}\n"
     ]
    }
   ],
   "source": [
    "# Compute optimal class weights\n",
    "\n",
    "# Obtain y_train integer labels and flatten\n",
    "y_int_labels = np.argmax(y_train, axis=1)\n",
    "\n",
    "# Compute class weights based on emotion label counts\n",
    "computed_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_int_labels),\n",
    "    y=y_int_labels\n",
    ")\n",
    "\n",
    "# Convert the computed weights array to a dictionary\n",
    "emotion_weights = {i: weight for i, weight in enumerate(computed_weights)}\n",
    "\n",
    "# Print the class optimal class weights derived\n",
    "print(\"Emotion Class Weights:\", emotion_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c5375-09ed-4242-b174-6ebbf5c01984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 1.3513 - accuracy: 0.4636\n",
      "Epoch 1: val_accuracy improved from -inf to 0.45747, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 703s 238ms/step - loss: 1.3513 - accuracy: 0.4636 - val_loss: 1.4492 - val_accuracy: 0.4575 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 1.0350 - accuracy: 0.5854\n",
      "Epoch 2: val_accuracy improved from 0.45747 to 0.63031, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 697s 237ms/step - loss: 1.0350 - accuracy: 0.5854 - val_loss: 0.9839 - val_accuracy: 0.6303 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.8391 - accuracy: 0.6600\n",
      "Epoch 3: val_accuracy improved from 0.63031 to 0.70556, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 697s 237ms/step - loss: 0.8391 - accuracy: 0.6600 - val_loss: 0.7817 - val_accuracy: 0.7056 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.6409 - accuracy: 0.7344\n",
      "Epoch 4: val_accuracy improved from 0.70556 to 0.76497, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 691s 235ms/step - loss: 0.6409 - accuracy: 0.7344 - val_loss: 0.6362 - val_accuracy: 0.7650 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.4788 - accuracy: 0.7991\n",
      "Epoch 5: val_accuracy improved from 0.76497 to 0.82786, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 696s 237ms/step - loss: 0.4788 - accuracy: 0.7991 - val_loss: 0.4808 - val_accuracy: 0.8279 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.3657 - accuracy: 0.8467\n",
      "Epoch 6: val_accuracy improved from 0.82786 to 0.89005, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 695s 236ms/step - loss: 0.3657 - accuracy: 0.8467 - val_loss: 0.3131 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.8774\n",
      "Epoch 7: val_accuracy improved from 0.89005 to 0.91806, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 691s 235ms/step - loss: 0.2918 - accuracy: 0.8774 - val_loss: 0.2342 - val_accuracy: 0.9181 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.9001\n",
      "Epoch 8: val_accuracy improved from 0.91806 to 0.93566, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 690s 234ms/step - loss: 0.2377 - accuracy: 0.9001 - val_loss: 0.1905 - val_accuracy: 0.9357 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.9144\n",
      "Epoch 9: val_accuracy improved from 0.93566 to 0.94666, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 690s 234ms/step - loss: 0.2063 - accuracy: 0.9144 - val_loss: 0.1636 - val_accuracy: 0.9467 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.1825 - accuracy: 0.9242\n",
      "Epoch 10: val_accuracy improved from 0.94666 to 0.94855, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 690s 234ms/step - loss: 0.1825 - accuracy: 0.9242 - val_loss: 0.1565 - val_accuracy: 0.9486 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.9329\n",
      "Epoch 11: val_accuracy improved from 0.94855 to 0.95159, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 688s 234ms/step - loss: 0.1620 - accuracy: 0.9329 - val_loss: 0.1459 - val_accuracy: 0.9516 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 0.9384\n",
      "Epoch 12: val_accuracy improved from 0.95159 to 0.95811, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 688s 234ms/step - loss: 0.1489 - accuracy: 0.9384 - val_loss: 0.1284 - val_accuracy: 0.9581 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.1389 - accuracy: 0.9430\n",
      "Epoch 13: val_accuracy improved from 0.95811 to 0.96530, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 688s 234ms/step - loss: 0.1389 - accuracy: 0.9430 - val_loss: 0.1067 - val_accuracy: 0.9653 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.9488\n",
      "Epoch 14: val_accuracy improved from 0.96530 to 0.97012, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 688s 234ms/step - loss: 0.1258 - accuracy: 0.9488 - val_loss: 0.0931 - val_accuracy: 0.9701 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9529\n",
      "Epoch 15: val_accuracy improved from 0.97012 to 0.97189, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 688s 234ms/step - loss: 0.1166 - accuracy: 0.9529 - val_loss: 0.0876 - val_accuracy: 0.9719 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9547\n",
      "Epoch 16: val_accuracy improved from 0.97189 to 0.97713, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 688s 234ms/step - loss: 0.1133 - accuracy: 0.9547 - val_loss: 0.0743 - val_accuracy: 0.9771 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9578\n",
      "Epoch 17: val_accuracy did not improve from 0.97713\n",
      "2944/2944 [==============================] - 690s 234ms/step - loss: 0.1054 - accuracy: 0.9578 - val_loss: 0.0781 - val_accuracy: 0.9748 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.9607\n",
      "Epoch 18: val_accuracy improved from 0.97713 to 0.98308, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 696s 237ms/step - loss: 0.0977 - accuracy: 0.9607 - val_loss: 0.0576 - val_accuracy: 0.9831 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9620\n",
      "Epoch 19: val_accuracy did not improve from 0.98308\n",
      "2944/2944 [==============================] - 692s 235ms/step - loss: 0.0944 - accuracy: 0.9620 - val_loss: 0.0631 - val_accuracy: 0.9814 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9647\n",
      "Epoch 20: val_accuracy improved from 0.98308 to 0.98329, saving model to emotion_model_CSV.h5\n",
      "2944/2944 [==============================] - 690s 234ms/step - loss: 0.0882 - accuracy: 0.9647 - val_loss: 0.0545 - val_accuracy: 0.9833 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9667\n",
      "Epoch 21: val_accuracy did not improve from 0.98329\n",
      "2944/2944 [==============================] - 690s 234ms/step - loss: 0.0851 - accuracy: 0.9667 - val_loss: 0.0552 - val_accuracy: 0.9829 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2944/2944 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9666"
     ]
    }
   ],
   "source": [
    "#see facical checkpointer \n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy', # Value to monitor\n",
    "    patience=10, # Wait for 10 epochs\n",
    "    verbose=0,  # Verbosity (prints nothing)\n",
    "    mode=\"max\",  # Mode\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Learning rate reduction \n",
    "lr_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_loss', # Value to monitor\n",
    "    factor=0.2,  # Reduction factor\n",
    "    patience=5,  # Wait for 5 epochs\n",
    "    verbose=0,   # Verbosity (prints nothing)\n",
    "    mode='min',  # Mode\n",
    "    min_lr=1e-6  # Minimum learning rate\n",
    ")\n",
    "\n",
    "# Save the best model observed\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'emotion_model_CSV.h5', # Model export filename\n",
    "    monitor=\"val_accuracy\", # Value to monitor\n",
    "    verbose=1,  # Verbosity (prints details about new model saved)\n",
    "    mode=\"max\", # Mode\n",
    "    save_best_only=True # Save when the best model is observed\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    class_weight=emotion_weights, # Use the derived optimal for class weights\n",
    "    callbacks=[early_stop, lr_reduction, model_checkpoint],  \n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f214ac60-826d-497a-9a6a-d7ae44895d08",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936132ad-bf7f-4ea4-91a9-998cb74c4d0b",
   "metadata": {},
   "source": [
    "### Accuracy and Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99571f1-c5cc-4628-8e07-cff443b82ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Accuracy (Train)')\n",
    "plt.plot(history.history['val_accuracy'], label='Accuracy (Validation)')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(prop={'size': 8})\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Loss (Train)')\n",
    "plt.plot(history.history['val_loss'], label='Loss (Validation)')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(prop={'size': 8})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc1324-b3ab-4dc8-ba2f-2dcee5db94f6",
   "metadata": {},
   "source": [
    "#### Compute evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df052bd-ffa4-4971-b536-3d6346724fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model \n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Retrieve predicted classes\n",
    "y_pred = model.predict(X_test)  # Predict using the test set\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predictions to class indices\n",
    "\n",
    "# Retrieve true labels\n",
    "y_true = np.argmax(y_test, axis=1)  # Convert true labels to class indices if y_test is one-hot encoded\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_true, y_pred_classes, average='weighted')  # Precision\n",
    "recall = recall_score(y_true, y_pred_classes, average='weighted')        # Recall\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')                # F1 score\n",
    "\n",
    "# Print results\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d3c47-65c6-432d-b16f-5db4b98d5922",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d774fe5c-fde1-44e0-a25d-c2a065d42ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# Retrieve emotion labels from Emotion column of feature df\n",
    "label_names = feature_df['Emotion'].unique()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_names, yticklabels=label_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Emotion Recognition - Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaa0dec-eb8a-42c7-baa6-38622328f222",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e9368-64f3-4218-8f06-2631c4d6ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_true, y_pred_classes, target_names=label_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c1e215-9a7a-47c2-9714-e81417123bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0947c409-6408-4055-8847-f82c1cdeb0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd575289-1277-47d2-9ccd-9fd24de4ca83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ef33d-2b35-4bf0-b750-137e2c16661f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff62348-1859-478e-af08-ddf4467ce765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aca682-f76b-4bb5-bce2-690d49858925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2963805a-b717-4422-8a9a-45afcdf6c58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081e059-1759-4df8-9595-c602a032aebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22afe566-20ea-4f3a-b52e-dc399d9ddabc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow GPU Kernel 2",
   "language": "python",
   "name": "tensor-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
