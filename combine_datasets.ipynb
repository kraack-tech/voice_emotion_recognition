{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3eb528d-9277-4426-8cb5-46e6c172a07f",
   "metadata": {},
   "source": [
    "# Speech Emotion Recognition: Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab62d98-c0d3-4251-b5a9-d55bfdb144e2",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ded63f72-e01b-47ec-95ff-388d34960bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8aac75-b1d1-4c6e-a037-ae01035815c6",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143b3deb-7085-4444-a058-1fedf00ca906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets used for training the model (wav/mp4)\n",
    "\n",
    "# CREMA-D (Crowd-sourced Emotional Multimodal Actors Dataset)\n",
    "# Reference: CREMA-D: Crowd-sourced Emotional Multimodal Actors Dataset. Available at: https://github.com/CheyneyComputerScience/CREMA-D\n",
    "CREMA = \"CREMA/AudioWAV/\" # Path to audio files (WAV)\n",
    "\n",
    "# RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)\n",
    "# Reference: \"The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)\" by Livingstone & Russo is licensed under CC BY-NA-SC 4.0. Available at: https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\n",
    "RAVDESS = \"RAVDESS/audio_speech_actors_01-24/\" # Path to audio files\n",
    "\n",
    "# SAVEE (Surrey Audio-Visual Expressed Emotion)\n",
    "# Reference: Surrey Audio-Visual Expressed Emotion (SAVEE) Dataset. [Online]. Available: http://kahlan.eps.surrey.ac.uk/savee/\n",
    "SAVEE = \"SAVEE/ALL/\" # Path to audio files (WAV)\n",
    "\n",
    "# TESS (Toronto Emotional Speech Set)\n",
    "# Reference: Toronto Emotional Speech Set. [Online]. Available: https://tspace.library.utoronto.ca/handle/1807/24487\n",
    "TESS = \"TESS/\" # Path to audio files (WAV)\n",
    "\n",
    "# ESD (Emotional Speech Dataset)\n",
    "# This model only use the English speakers (i.e., Mandarin speakers 0-10 are excluded) \n",
    "# Reference: Kun Zhou, Berrak Sisman, Rui Liu and Haizhou Li, \"Seen and unseen emotional style transfer for voice conversion with a new emotional speech dataset\" ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). [Online]. Available: https://github.com/HLTSingapore/Emotional-Speech-Data?tab=readme-ov-file\n",
    "ESD  = \"ESD/\" # Path to audio files (WAV)\n",
    "\n",
    "# MELD (Multimodal EmotionLines Dataset)\n",
    "# Wav audio files are extracted from video files contained within the dataset.\n",
    "# References: \n",
    "# S. Poria, D. Hazarika, N. Majumder, G. Naik, R. Mihalcea, E. Cambria. MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversation. (2018).\n",
    "# Chen, S.Y., Hsu, C.C., Kuo, C.C. and Ku, L.W. EmotionLines: An Emotion Corpus of Multi-Party Conversations. arXiv preprint arXiv:1802.08379 (2018).\n",
    "# Available: https://github.com/declare-lab/MELD\n",
    "MELD = 'MELD/train_splits/'  # Path to video files (mp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a64645-8bd9-4b2b-82a7-906e1f990079",
   "metadata": {},
   "source": [
    "### CREMA-D Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64df7d9-ebd2-4f4e-830b-8a104133484a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREMA-D - DataFrame head:\n",
      "                                 File  Emotion\n",
      "0  CREMA/AudioWAV/1001_DFA_ANG_XX.wav    angry\n",
      "1  CREMA/AudioWAV/1001_DFA_DIS_XX.wav  disgust\n",
      "2  CREMA/AudioWAV/1001_DFA_FEA_XX.wav     fear\n",
      "3  CREMA/AudioWAV/1001_DFA_HAP_XX.wav    happy\n",
      "4  CREMA/AudioWAV/1001_DFA_NEU_XX.wav  neutral \n",
      "\n",
      "CREMA-D - Emotion counts:\n",
      "Emotion\n",
      "angry      1271\n",
      "disgust    1271\n",
      "fear       1271\n",
      "happy      1271\n",
      "sad        1271\n",
      "neutral    1087\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Generate CREMA-D dataframe\n",
    "\n",
    "# Emotion labels: Maps emotions obtained from the filename to a string value\n",
    "emotion_map = {\n",
    "    'SAD': 'sad',\n",
    "    'ANG': 'angry',\n",
    "    'DIS': 'disgust',\n",
    "    'FEA': 'fear',\n",
    "    'HAP': 'happy',\n",
    "    'NEU': 'neutral'\n",
    "}\n",
    "\n",
    "# Create Panda dataframe using paths and emotion associated with the corresponding file\n",
    "crema_df = pd.DataFrame([\n",
    "    {\n",
    "        'File': os.path.join(CREMA, file),\n",
    "        'Emotion': emotion_map.get(file.split('_')[2], 'Unknown')\n",
    "    }\n",
    "    for file in os.listdir(CREMA)\n",
    "])\n",
    "\n",
    "# Print dataframe header\n",
    "print(\"CREMA-D - DataFrame head:\")\n",
    "print(crema_df.head(), \"\\n\")\n",
    "\n",
    "# Print emotion counts \n",
    "print(\"CREMA-D - Emotion counts:\")\n",
    "print(crema_df['Emotion'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517d313-f057-4d51-83a1-4c9cbd36d657",
   "metadata": {},
   "source": [
    "### RAVDESS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37dedeef-02ea-48f9-9b74-df1415333904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAVDESS - DataFrame head:\n",
      "                                                File  Emotion\n",
      "0  RAVDESS/audio_speech_actors_01-24/Actor_01\\03-...  neutral\n",
      "1  RAVDESS/audio_speech_actors_01-24/Actor_01\\03-...  neutral\n",
      "2  RAVDESS/audio_speech_actors_01-24/Actor_01\\03-...  neutral\n",
      "3  RAVDESS/audio_speech_actors_01-24/Actor_01\\03-...  neutral\n",
      "4  RAVDESS/audio_speech_actors_01-24/Actor_01\\03-...    happy \n",
      "\n",
      "RAVDESS - Emotion counts:\n",
      "Emotion\n",
      "happy       192\n",
      "sad         192\n",
      "angry       192\n",
      "fear        192\n",
      "disgust     192\n",
      "surprise    192\n",
      "neutral      96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Generate RAVDESS dataframe\n",
    "\n",
    "# Emotion labels: Map emotions obtained from the integer values of the filename to a string value\n",
    "emotion_map = {\n",
    "    1: 'neutral',\n",
    "    #2: 'calm',  # Excluding the calm emotion as it's only features in the RAVDESS dataset (N=192 is too small for the model)\n",
    "    3: 'happy',\n",
    "    4: 'sad',\n",
    "    5: 'angry',\n",
    "    6: 'fear',\n",
    "    7: 'disgust',\n",
    "    8: 'surprise'\n",
    "}\n",
    "\n",
    "# Create Panda dataframe using paths and emotion associated with the corresponding file (excluding 'calm')\n",
    "ravdess_df = pd.DataFrame([\n",
    "    {\n",
    "        'File': os.path.join(RAVDESS, actor_dir, file_name),\n",
    "        'Emotion': emotion_map.get(int(file_name.split('-')[2]), 'Unknown')\n",
    "    }\n",
    "    for actor_dir in os.listdir(RAVDESS)\n",
    "    for file_name in os.listdir(os.path.join(RAVDESS, actor_dir))\n",
    "    if int(file_name.split('-')[2]) != 2  # Exclude 'calm' (emotion with integer value of 2)\n",
    "])\n",
    "\n",
    "# Print dataframe header\n",
    "print(\"RAVDESS - DataFrame head:\")\n",
    "print(ravdess_df.head(), \"\\n\")\n",
    "\n",
    "# Print emotion counts \n",
    "print(\"RAVDESS - Emotion counts:\")\n",
    "print(ravdess_df['Emotion'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b954efbf-e7d5-4d33-a062-5a2ec34ef0eb",
   "metadata": {},
   "source": [
    "### SAVEE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2503a94-ee71-43b6-aaae-36aae14ef2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVEE - DataFrame head:\n",
      "                   File Emotion\n",
      "0  SAVEE/ALL/DC_a01.wav   angry\n",
      "1  SAVEE/ALL/DC_a02.wav   angry\n",
      "2  SAVEE/ALL/DC_a03.wav   angry\n",
      "3  SAVEE/ALL/DC_a04.wav   angry\n",
      "4  SAVEE/ALL/DC_a05.wav   angry \n",
      "\n",
      "SAVEE - Emotion counts:\n",
      "Emotion\n",
      "neutral     120\n",
      "angry        60\n",
      "disgust      60\n",
      "fear         60\n",
      "happy        60\n",
      "sad          60\n",
      "surprise     60\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Generate SAVEE dataframe\n",
    "\n",
    "# Map emotion codes to labels\n",
    "emotion_map = {\n",
    "    'a': 'angry',\n",
    "    'd': 'disgust',\n",
    "    'f': 'fear',\n",
    "    'h': 'happy',\n",
    "    'n': 'neutral',\n",
    "    'sa': 'sad',\n",
    "    'su':'surprise'\n",
    "}\n",
    "\n",
    "# Create Panda dataframe using paths and emotion associated with the corresponding file (excluding 'calm')\n",
    "savee_df = pd.DataFrame([\n",
    "    {\n",
    "        'File': os.path.join(SAVEE, file),\n",
    "        'Emotion': emotion_map.get(file.split('_')[1][:-6])  # Map to emotion (excluding the last 6 characters) \n",
    "    }\n",
    "    for file in os.listdir(SAVEE)\n",
    "])\n",
    "\n",
    "# Print dataframe header\n",
    "print(\"SAVEE - DataFrame head:\")\n",
    "print(savee_df.head(), \"\\n\")\n",
    "\n",
    "# Print emotion counts \n",
    "print(\"SAVEE - Emotion counts:\")\n",
    "print(savee_df['Emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760b1d14-1815-4003-86b7-c6587e2954e8",
   "metadata": {},
   "source": [
    "### TESS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb826ca4-2cdb-40d4-a035-26f8abd2f1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESS - DataFrame head:\n",
      "                                File Emotion\n",
      "0  TESS/OAF_angry\\OAF_back_angry.wav   angry\n",
      "1   TESS/OAF_angry\\OAF_bar_angry.wav   angry\n",
      "2  TESS/OAF_angry\\OAF_base_angry.wav   angry\n",
      "3  TESS/OAF_angry\\OAF_bath_angry.wav   angry\n",
      "4  TESS/OAF_angry\\OAF_bean_angry.wav   angry \n",
      "\n",
      "TESS - Emotion counts:\n",
      "Emotion\n",
      "angry       400\n",
      "disgust     400\n",
      "fear        400\n",
      "happy       400\n",
      "neutral     400\n",
      "surprise    400\n",
      "sad         400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Generate TESS dataframe\n",
    "\n",
    "# Create Panda dataframe using paths and emotion associated with the corresponding file (renaming ps to 'surprise')\n",
    "tess_df = pd.DataFrame([\n",
    "    {\n",
    "        'File': os.path.join(TESS, dir, file),\n",
    "        'Emotion': 'surprise' if file.split('_')[-1].split('.')[0] == 'ps' else file.split('_')[-1].split('.')[0]  # Handle 'ps' as 'surprise' and remove '.wav'\n",
    "    }\n",
    "    for dir in os.listdir(TESS)\n",
    "    for file in os.listdir(os.path.join(TESS, dir))\n",
    "])\n",
    "\n",
    "# Print dataframe header\n",
    "print(\"TESS - DataFrame head:\")\n",
    "print(tess_df.head(), \"\\n\")\n",
    "\n",
    "# Print emotion counts \n",
    "print(\"TESS - Emotion counts:\")\n",
    "print(tess_df['Emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd40d18-44bf-4655-995e-798da35cc784",
   "metadata": {},
   "source": [
    "### ESD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5662727a-3ed4-4abf-84b2-d6093c2888b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESS - DataFrame head:\n",
      "                             File Emotion\n",
      "0  ESD/0011\\Angry\\0011_000351.wav   angry\n",
      "1  ESD/0011\\Angry\\0011_000352.wav   angry\n",
      "2  ESD/0011\\Angry\\0011_000353.wav   angry\n",
      "3  ESD/0011\\Angry\\0011_000354.wav   angry\n",
      "4  ESD/0011\\Angry\\0011_000355.wav   angry \n",
      "\n",
      "TESS - Emotion counts:\n",
      "Emotion\n",
      "angry       3500\n",
      "happy       3500\n",
      "neutral     3500\n",
      "sad         3500\n",
      "surprise    3500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Generate ESD dataframe\n",
    "\n",
    "# Create Panda dataframe using speaker and emotions paths associated with corresponding file\n",
    "esd_df = pd.DataFrame([\n",
    "    {\n",
    "        'File': os.path.join(ESD, speaker_folder, emotion_folder, audio_file),\n",
    "        'Emotion': emotion_folder.lower()  # Using the emotion folder as label\n",
    "    }\n",
    "    for speaker_folder in os.listdir(ESD)  # Process speaker folders (0011 - 0020)\n",
    "    for emotion_folder in os.listdir(os.path.join(ESD, speaker_folder)) # Process all emotion folders (e.g., 'Neutral' or 'Happy') \n",
    "    for audio_file in os.listdir(os.path.join(ESD, speaker_folder, emotion_folder))  # Process  all audio files\n",
    "])\n",
    "\n",
    "# Print dataframe header\n",
    "print(\"TESS - DataFrame head:\")\n",
    "print(esd_df.head(), \"\\n\")\n",
    "\n",
    "# Print emotion value counts \n",
    "print(\"TESS - Emotion counts:\")\n",
    "print(esd_df['Emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd874c-2c40-4e1a-9446-15b62d4ae829",
   "metadata": {},
   "source": [
    "### Meld Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3af5d98e-02b6-48c9-b02e-209a3d58407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file containing corresponding emotions for the videos\n",
    "MELD_csv = pd.read_csv('MELD/train_sent_emo.csv')  # Path to CSV file containing corresponding emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8914ab08-9b29-45d7-a439-9f1e89c13e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for extacted audio (Wav format)\n",
    "MELD_WAV = 'MELD/train_splits_audio' \n",
    "\n",
    "# Create the output audio directory (if it doesn't exist)\n",
    "os.makedirs(MELD_WAV, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe872e7a-adbd-460d-b33e-c74242e82316",
   "metadata": {},
   "source": [
    "#### Extract Audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d088edc-9ea3-4eb7-8230-5d44a60cfa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the CSV rows and extract audio from the corresponding mp4 video files\n",
    "for _, row in MELD_csv.iterrows():\n",
    "    # Obtain video filename based on the corresponding Dialogue_ID and Utterance_ID row values\n",
    "    video_filename = f'dia{row[\"Dialogue_ID\"]}_utt{row[\"Utterance_ID\"]}.mp4'\n",
    "    video_path = os.path.join(MELD, video_filename) # Join\n",
    "\n",
    "    # Define \n",
    "    audio_filename = video_filename.replace('.mp4', '.wav') # Audio file name remains the same except for extension type (WAV)\n",
    "    audio_path = os.path.join(MELD_WAV, audio_filename) \n",
    "\n",
    "    # Check if the video file exists\n",
    "    if os.path.isfile(video_path):\n",
    "        # Check if the audio file already exists\n",
    "        if not os.path.isfile(audio_path):\n",
    "            #print(f\"Processing file: {video_path}\")\n",
    "            \n",
    "            # Extract audio using ffmpeg\n",
    "            command = f'ffmpeg -i \"{video_path}\" -q:a 0 -map a \"{audio_path}\"'\n",
    "            result = subprocess.run(command, shell=True)\n",
    "    else:\n",
    "        print(f\"File does not exist: {video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ce005-3799-4003-b6b7-7ee807ace399",
   "metadata": {},
   "source": [
    "#### Extract Emotions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff23b8e0-dfbc-44f5-b170-02135210ae07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MELD - DataFrame head:\n",
      "                                    File   Emotion\n",
      "0  MELD/train_splits_audio\\dia0_utt0.wav   neutral\n",
      "1  MELD/train_splits_audio\\dia0_utt1.wav   neutral\n",
      "2  MELD/train_splits_audio\\dia0_utt2.wav   neutral\n",
      "3  MELD/train_splits_audio\\dia0_utt3.wav   neutral\n",
      "4  MELD/train_splits_audio\\dia0_utt4.wav  surprise \n",
      "\n",
      "MELD - Emotion counts:\n",
      "Emotion\n",
      "neutral     4709\n",
      "happy       1743\n",
      "surprise    1205\n",
      "angry       1109\n",
      "sad          683\n",
      "disgust      271\n",
      "fear         268\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mapping of emotions to align with labels from the other datasets\n",
    "emotion_map = {\n",
    "    'joy': 'happy',\n",
    "    'anger': 'angry',\n",
    "    'sadness': 'sad'\n",
    "}\n",
    "\n",
    "# Create Panda dataframe using the audio file and associated entry of the csv document.\n",
    "meld_df = pd.DataFrame([\n",
    "    {\n",
    "        'File': os.path.join(MELD_WAV, f'dia{row[\"Dialogue_ID\"]}_utt{row[\"Utterance_ID\"]}.wav'),\n",
    "        'Emotion': emotion_map.get(row['Emotion'].lower(), row['Emotion'].lower())\n",
    "    }\n",
    "    for _, row in MELD_csv.iterrows()\n",
    "    if os.path.isfile(os.path.join(MELD_WAV, f'dia{row[\"Dialogue_ID\"]}_utt{row[\"Utterance_ID\"]}.wav'))\n",
    "])\n",
    "\n",
    "# Print dataframe header\n",
    "print(\"MELD - DataFrame head:\")\n",
    "print(meld_df.head(), \"\\n\")\n",
    "\n",
    "# Print emotion value counts \n",
    "print(\"MELD - Emotion counts:\")\n",
    "print(meld_df['Emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d4e3f-2fd8-4a11-b3d4-7b0e9e936d65",
   "metadata": {},
   "source": [
    "## Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48274140-4579-49a1-abcd-f86e489677f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined emotion DataFrame header:\n",
      "                                 File  Emotion\n",
      "0  CREMA/AudioWAV/1001_DFA_ANG_XX.wav    angry\n",
      "1  CREMA/AudioWAV/1001_DFA_DIS_XX.wav  disgust\n",
      "2  CREMA/AudioWAV/1001_DFA_FEA_XX.wav     fear\n",
      "3  CREMA/AudioWAV/1001_DFA_HAP_XX.wav    happy\n",
      "4  CREMA/AudioWAV/1001_DFA_NEU_XX.wav  neutral \n",
      "\n",
      "Combined emotion DataFrame value counts:\n",
      "Emotion\n",
      "neutral     9912\n",
      "happy       7166\n",
      "angry       6532\n",
      "sad         6106\n",
      "surprise    5357\n",
      "disgust     2194\n",
      "fear        2191\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "emotion_df = pd.concat([crema_df, ravdess_df, savee_df, tess_df, esd_df, meld_df], axis = 0)  \n",
    "\n",
    "# Print combined dataframe header\n",
    "print(\"Combined emotion DataFrame header:\")\n",
    "print(emotion_df.head(), \"\\n\")\n",
    "\n",
    "# Print combined emotion value counts \n",
    "print(\"Combined emotion DataFrame value counts:\")\n",
    "print(emotion_df['Emotion'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8043b09-b5dc-4f9b-b979-6b17a8a29089",
   "metadata": {},
   "source": [
    "## Save CSV-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e30f56e-0c56-4b36-bcea-d9695bd2edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_df.to_csv(\"emotion_df.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow GPU Kernel",
   "language": "python",
   "name": "tensor-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
