{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53ff72c-82d6-4bb8-afa1-d8ec61699218",
   "metadata": {},
   "source": [
    "# Voice Emotion Recognition: Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdebf20-ae2e-4c96-a8d9-c85c30ba3483",
   "metadata": {},
   "source": [
    "#### Detects emotions in real time based on extracted audio features (feature_extractiton.ipynb) and makes predictions using the trained model (feature_extractiton.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3077af74-4634-455f-a502-4d723d0f0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b663c8-b815-4b88-84e0-93912bdc84e1",
   "metadata": {},
   "source": [
    "#### Import audio feature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ef755f86-86e2-45b1-a4b1-03e2f6049ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2675</th>\n",
       "      <th>2676</th>\n",
       "      <th>2677</th>\n",
       "      <th>2678</th>\n",
       "      <th>2679</th>\n",
       "      <th>2680</th>\n",
       "      <th>2681</th>\n",
       "      <th>2682</th>\n",
       "      <th>2683</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.092285</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>0.049805</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.054199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129883</td>\n",
       "      <td>0.161621</td>\n",
       "      <td>0.187012</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.092773</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.057617</td>\n",
       "      <td>0.061523</td>\n",
       "      <td>0.084961</td>\n",
       "      <td>0.147949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.092285</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>0.049805</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.054199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083984</td>\n",
       "      <td>0.117676</td>\n",
       "      <td>0.141113</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.051758</td>\n",
       "      <td>0.045898</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.061035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061035</td>\n",
       "      <td>0.092285</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>0.103516</td>\n",
       "      <td>0.084961</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.035645</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235471</th>\n",
       "      <td>0.083984</td>\n",
       "      <td>0.133789</td>\n",
       "      <td>0.161133</td>\n",
       "      <td>0.153320</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.086426</td>\n",
       "      <td>0.095215</td>\n",
       "      <td>0.108398</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.996235</td>\n",
       "      <td>-4.265385</td>\n",
       "      <td>-1.865951</td>\n",
       "      <td>-2.166432</td>\n",
       "      <td>-17.060484</td>\n",
       "      <td>-9.683095</td>\n",
       "      <td>-0.542660</td>\n",
       "      <td>-0.719571</td>\n",
       "      <td>-6.080200</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235472</th>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.099609</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>0.052734</td>\n",
       "      <td>0.036621</td>\n",
       "      <td>0.032715</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.155140</td>\n",
       "      <td>-3.369991</td>\n",
       "      <td>-1.089657</td>\n",
       "      <td>0.174891</td>\n",
       "      <td>-19.147015</td>\n",
       "      <td>-12.684088</td>\n",
       "      <td>0.123865</td>\n",
       "      <td>-1.245382</td>\n",
       "      <td>-5.587992</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235473</th>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.176758</td>\n",
       "      <td>0.139648</td>\n",
       "      <td>0.121094</td>\n",
       "      <td>0.112793</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.153809</td>\n",
       "      <td>0.174805</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.238156</td>\n",
       "      <td>-2.266622</td>\n",
       "      <td>0.860346</td>\n",
       "      <td>-1.415168</td>\n",
       "      <td>-17.360427</td>\n",
       "      <td>-9.504957</td>\n",
       "      <td>0.042696</td>\n",
       "      <td>-0.656188</td>\n",
       "      <td>-5.901685</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235474</th>\n",
       "      <td>0.045898</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.094727</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.051758</td>\n",
       "      <td>0.035645</td>\n",
       "      <td>0.032715</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.817496</td>\n",
       "      <td>-7.855257</td>\n",
       "      <td>-4.327174</td>\n",
       "      <td>-6.591506</td>\n",
       "      <td>-18.465111</td>\n",
       "      <td>-14.346745</td>\n",
       "      <td>0.730882</td>\n",
       "      <td>-8.990791</td>\n",
       "      <td>-5.316560</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235475</th>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.116699</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>0.076660</td>\n",
       "      <td>0.082520</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.012169</td>\n",
       "      <td>0.884069</td>\n",
       "      <td>2.511671</td>\n",
       "      <td>0.486484</td>\n",
       "      <td>-17.122528</td>\n",
       "      <td>-15.097058</td>\n",
       "      <td>-1.169470</td>\n",
       "      <td>-0.801278</td>\n",
       "      <td>-4.412979</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235476 rows × 2685 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0       0.058594  0.092285  0.115723  0.106445  0.087891  0.066406  0.049805   \n",
       "1       0.129883  0.161621  0.187012  0.113281  0.092773  0.073242  0.057617   \n",
       "2       0.058594  0.092285  0.115723  0.106445  0.087891  0.066406  0.049805   \n",
       "3       0.083984  0.117676  0.141113  0.109375  0.089844  0.068359  0.051758   \n",
       "4       0.061035  0.092285  0.115723  0.103516  0.084961  0.063965  0.048340   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "235471  0.083984  0.133789  0.161133  0.153320  0.117188  0.093750  0.086426   \n",
       "235472  0.046875  0.078125  0.099609  0.097656  0.076172  0.052734  0.036621   \n",
       "235473  0.085938  0.145508  0.187500  0.176758  0.139648  0.121094  0.112793   \n",
       "235474  0.045898  0.076172  0.097656  0.094727  0.074219  0.051758  0.035645   \n",
       "235475  0.054688  0.097656  0.116699  0.111816  0.091797  0.076660  0.082520   \n",
       "\n",
       "               7         8         9  ...       2675      2676      2677  \\\n",
       "0       0.043945  0.038086  0.054199  ...   0.000000  0.000000  0.000000   \n",
       "1       0.061523  0.084961  0.147949  ...   0.000000  0.000000  0.000000   \n",
       "2       0.043945  0.038086  0.054199  ...   0.000000  0.000000  0.000000   \n",
       "3       0.045898  0.041016  0.061035  ...   0.000000  0.000000  0.000000   \n",
       "4       0.041992  0.035645  0.050781  ...   0.000000  0.000000  0.000000   \n",
       "...          ...       ...       ...  ...        ...       ...       ...   \n",
       "235471  0.095215  0.108398  0.132812  ... -11.996235 -4.265385 -1.865951   \n",
       "235472  0.032715  0.029297  0.035156  ... -11.155140 -3.369991 -1.089657   \n",
       "235473  0.130859  0.153809  0.174805  ... -12.238156 -2.266622  0.860346   \n",
       "235474  0.032715  0.029297  0.034180  ...  -4.817496 -7.855257 -4.327174   \n",
       "235475  0.117188  0.156250  0.183594  ...  -3.012169  0.884069  2.511671   \n",
       "\n",
       "            2678       2679       2680      2681      2682      2683  Emotion  \n",
       "0       0.000000   0.000000   0.000000  0.000000  0.000000  0.000000    angry  \n",
       "1       0.000000   0.000000   0.000000  0.000000  0.000000  0.000000    angry  \n",
       "2       0.000000   0.000000   0.000000  0.000000  0.000000  0.000000    angry  \n",
       "3       0.000000   0.000000   0.000000  0.000000  0.000000  0.000000    angry  \n",
       "4       0.000000   0.000000   0.000000  0.000000  0.000000  0.000000    angry  \n",
       "...          ...        ...        ...       ...       ...       ...      ...  \n",
       "235471 -2.166432 -17.060484  -9.683095 -0.542660 -0.719571 -6.080200    happy  \n",
       "235472  0.174891 -19.147015 -12.684088  0.123865 -1.245382 -5.587992    happy  \n",
       "235473 -1.415168 -17.360427  -9.504957  0.042696 -0.656188 -5.901685    happy  \n",
       "235474 -6.591506 -18.465111 -14.346745  0.730882 -8.990791 -5.316560    happy  \n",
       "235475  0.486484 -17.122528 -15.097058 -1.169470 -0.801278 -4.412979    happy  \n",
       "\n",
       "[235476 rows x 2685 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the extracted audio features from 'feature_extraction.ipynb' notebook\n",
    "# The file is approx. 9.4 GB, so it might take a while to load \n",
    "feature_df = pd.read_csv('./extracted_features.csv')\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff12b3c-09bc-4bdb-8aaf-cb24a2ff1d73",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ad555573-712f-402f-af0d-0bda6f5d8a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "X_train: (188380, 2684, 1), y_train: (188380, 7)\n",
      "Test shape:\n",
      "X_test: (47096, 2684, 1), y_test: (47096, 7)\n"
     ]
    }
   ],
   "source": [
    "# Define extracted audio features (X) and emotion labels (Y)\n",
    "features = feature_df.iloc[:, :-1].values  # All comlumns feature columns\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "labels = encoder.fit_transform(feature_df[['Emotion']]) # One-hot encode emotions labels and reshape\n",
    "\n",
    "# Split data into training and test sets (80/20%)\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Scale the data using StandardScaler and reshape \n",
    "scaler = StandardScaler()\n",
    "X_train = np.expand_dims(scaler.fit_transform(x_train), axis=-1) # Training data\n",
    "X_test = np.expand_dims(scaler.transform(x_test), axis=-1) # Test data\n",
    "\n",
    "# Print shapes of training and test data\n",
    "print(f\"Training shape:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Test shape:\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c1d40e-b342-447a-8a96-e26372a2c809",
   "metadata": {},
   "source": [
    "## Data augmentation and audio feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "420611c1-0918-4845-a4cb-17ed87e5eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import augmentation function from the 'feature_extraction'  notebook.\n",
    "import nbimporter\n",
    "from feature_extraction import add_noise, dynamic_compression, pitch_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "480b3943-44f6-4e92-9f0e-c0278fca0f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified audio features extraction function from the  'extract_audio_features' notebook.\n",
    "def extract_audio_features(data, sr=22050, frame_length=2048, hop_length=512):\n",
    "    augmentations = [\n",
    "        (\"Original\", lambda x: x),  # Original audio\n",
    "        (\"Noise\", add_noise),  # Noise augmentation\n",
    "        (\"Dynamic Compression\", lambda x: dynamic_compression(x)),  # Dynamic compression augmentation\n",
    "        (\"Dynamic Compression and Noise\", lambda x: add_noise(dynamic_compression(x))),  # Dynamic compression + noise augmentation\n",
    "        (\"Pitch Shift\", lambda x: pitch_shift(x, sr)),  # Pitch shift augmentation\n",
    "        (\"Pitch Shift and Noise\", lambda x: add_noise(pitch_shift(x, sr))),  # Pitch shift + noise augmentation\n",
    "    ]\n",
    "\n",
    "    # Initialize list for extracted audio features\n",
    "    audio_features = [] \n",
    "\n",
    "    # Iterate over augmentations to apply and extract audio features\n",
    "    for name, augmentation in augmentations:\n",
    "        try:\n",
    "            augmented_data = augmentation(data)\n",
    "            \n",
    "            # Extract features (ZCR, RMS, MFCC)\n",
    "            features = np.hstack((\n",
    "                np.squeeze(librosa.feature.zero_crossing_rate(augmented_data, frame_length=frame_length, hop_length=hop_length)),\n",
    "                np.squeeze(librosa.feature.rms(y=augmented_data, frame_length=frame_length, hop_length=hop_length)),\n",
    "                np.squeeze(np.ravel(librosa.feature.mfcc(y=augmented_data, sr=sr, n_fft=frame_length, hop_length=hop_length).T))\n",
    "            ))\n",
    "\n",
    "            # Ensure the feature vector has the expected length (2684)\n",
    "            if features.size < 2684:\n",
    "                #print(f\"Warning: Feature size is smaller than expected for {name}, padding with zeros.\")\n",
    "                # Pad with zeros if the number of features is less than 2684\n",
    "                features = np.pad(features, (0, 2684 - features.size), mode='constant')\n",
    "            audio_features.append(features)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {name} audio: {e}\")\n",
    "            continue\n",
    "            \n",
    "    return np.array(audio_features[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728444b-6e78-41e0-82cf-42916a7917b1",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c56d4ab0-8bc6-40c8-9186-957f18258eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model saved using the  'voice_emotion_model.ipynb' notebook.\n",
    "model = load_model('emotion_model_CSV.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "9e1576a4-f753-4278-adfe-2e2cc3841915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads audio, extracts features, reshape, and make predictions on input audio file.\n",
    "def prediction(path):\n",
    "    # Load the audio file\n",
    "    audio_data, sample_rate = librosa.load(path, duration=2.81, offset=0.39)\n",
    "    \n",
    "    # Extract audio features\n",
    "    features = extract_audio_features(audio_data)\n",
    "        \n",
    "    # Reshape and scale the extracted features\n",
    "    features = np.reshape(features, newshape=(1, -1))  # Flatten features\n",
    "    scaled_features = scaler.transform(features)       # Scaling\n",
    "    final_features = np.expand_dims(scaled_features, axis=2)  # Add dimension\n",
    "\n",
    "    # Make prediction using the model\n",
    "    predictions = model.predict(final_features, verbose = 0)\n",
    "    \n",
    "    # Inverse transform to get the predicted emotion\n",
    "    predicted_emotion = encoder.inverse_transform(predictions)\n",
    "    \n",
    "    # return the predicted emotion\n",
    "    return predicted_emotion[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9189a1-cf6b-4589-8174-57d99ce94a11",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "efe9dfb4-07a0-4d67-b397-5d5c1bb1c129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates predictions and returns summary\n",
    "def evaluate_predictions(audio_files):\n",
    "    # Initialize summary counter\n",
    "    summary = {label: {\"correct\": 0, \"total\": len(files)} for label, files in audio_files.items()}\n",
    "\n",
    "    # Process files and update summary\n",
    "    for label, files in audio_files.items():\n",
    "        for file in files:\n",
    "            pred = prediction(file)\n",
    "            #print(f\"File: {file}, Predicted: {pred}, Expected: {label}\")\n",
    "            if pred is not None and pred.lower() == label.lower():\n",
    "                summary[label][\"correct\"] += 1\n",
    "\n",
    "\n",
    "    # Compute overall accuracy\n",
    "    total_correct = sum(counts[\"correct\"] for counts in summary.values())\n",
    "    total_files = sum(counts[\"total\"] for counts in summary.values())\n",
    "    overall_accuracy = (total_correct / total_files * 100) if total_files > 0 else 0\n",
    "\n",
    "    # Print summary\n",
    "    for emotion, counts in summary.items():\n",
    "        correct, total = counts[\"correct\"], counts[\"total\"]\n",
    "        accuracy = (correct / total * 100) if total > 0 else 0\n",
    "        print(f\"{emotion}: {correct}/{total} correct ({accuracy:.2f}%)\")\n",
    "    print(f\"\\nOverall Accuracy: {total_correct}/{total_files} ({overall_accuracy:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c68874-702e-462e-81b5-5ac94393d151",
   "metadata": {},
   "source": [
    "### Predicting audio files from the CREMA-D dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "a26fed01-55cd-4ba6-896c-5e0b785b5a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral: 2/2 correct (100.00%)\n",
      "Happy: 2/2 correct (100.00%)\n",
      "Sad: 2/2 correct (100.00%)\n",
      "Angry: 2/2 correct (100.00%)\n",
      "Fear: 2/2 correct (100.00%)\n",
      "Disgust: 2/2 correct (100.00%)\n",
      "\n",
      "Overall Accuracy: 12/12 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# Dictionary with audio fila paths for CREMA-D\n",
    "crema_files = {\n",
    "    \"Neutral\": [\"CREMA/AudioWAV/1001_IWW_NEU_XX.wav\", \"CREMA/AudioWAV/1069_IWL_NEU_XX.wav\"],\n",
    "    \"Happy\": [\"CREMA/AudioWAV/1009_IWL_HAP_XX.wav\", \"CREMA/AudioWAV/1083_IOM_HAP_XX.wav\"],\n",
    "    \"Sad\": [\"CREMA/AudioWAV/1040_WSI_SAD_XX.wav\", \"CREMA/AudioWAV/1091_WSI_SAD_XX.wav\"],\n",
    "    \"Angry\": [\"CREMA/AudioWAV/1091_IWL_ANG_XX.wav\", \"CREMA/AudioWAV/1013_IOM_ANG_XX.wav\"],\n",
    "    \"Fear\": [\"CREMA/AudioWAV/1013_IOM_FEA_XX.wav\", \"CREMA/AudioWAV/1046_DFA_FEA_XX.wav\"],\n",
    "    \"Disgust\": [\"CREMA/AudioWAV/1002_IWW_DIS_XX.wav\", \"CREMA/AudioWAV/1089_TAI_DIS_XX.wav\"]\n",
    "}\n",
    "\n",
    "# Make predictions and evaluate\n",
    "evaluate_predictions(crema_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ea88e4-c274-4114-9c37-7cea359e22cc",
   "metadata": {},
   "source": [
    "### Predicting audio files from the RAVDESS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "74d1487a-2970-4e09-8da5-b43b7a5cb847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral: 2/2 correct (100.00%)\n",
      "Happy: 2/2 correct (100.00%)\n",
      "Sad: 2/2 correct (100.00%)\n",
      "Angry: 2/2 correct (100.00%)\n",
      "Fear: 2/2 correct (100.00%)\n",
      "Disgust: 2/2 correct (100.00%)\n",
      "Surprise: 2/2 correct (100.00%)\n",
      "\n",
      "Overall Accuracy: 14/14 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# Dictionary with audio fila paths for RAVDESS dataset\n",
    "rav_files = {\n",
    "    \"Neutral\": [\"RAVDESS/Actor_01/03-01-01-01-02-02-01.wav\", \"RAVDESS/Actor_08/03-01-01-01-02-02-08.wav\"],\n",
    "    \"Happy\": [\"RAVDESS/Actor_16/03-01-03-02-01-02-16.wav\", \"RAVDESS/Actor_14/03-01-03-01-02-02-14.wav\"],\n",
    "    \"Sad\": [\"RAVDESS/Actor_10/03-01-04-01-01-02-10.wav\", \"RAVDESS/Actor_24/03-01-04-01-02-01-24.wav\"],\n",
    "    \"Angry\": [\"RAVDESS/Actor_13/03-01-05-02-02-01-13.wav\", \"RAVDESS/Actor_03/03-01-05-02-02-01-03.wav\"],\n",
    "    \"Fear\": [\"RAVDESS/Actor_18/03-01-06-02-01-01-18.wav\", \"RAVDESS/Actor_07/03-01-06-02-02-01-07.wav\"],\n",
    "    \"Disgust\": [\"RAVDESS/Actor_09/03-01-07-02-01-01-09.wav\", \"RAVDESS/Actor_22/03-01-07-02-01-01-22.wav\"],\n",
    "    \"Surprise\": [\"RAVDESS/Actor_08/03-01-08-01-02-02-08.wav\", \"RAVDESS/Actor_14/03-01-08-01-02-02-14.wav\"],\n",
    "}\n",
    "\n",
    "# Make predictions and evaluate\n",
    "evaluate_predictions(rav_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de25ff26-c446-4e6a-85bf-e30a5f1a937e",
   "metadata": {},
   "source": [
    "### Predicting audio files from the SAVEE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3c1b7b76-75b1-4743-9259-7a79f776e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral: 2/2 correct (100.00%)\n",
      "Happy: 2/2 correct (100.00%)\n",
      "Sad: 2/2 correct (100.00%)\n",
      "Angry: 2/2 correct (100.00%)\n",
      "Fear: 2/2 correct (100.00%)\n",
      "Disgust: 2/2 correct (100.00%)\n",
      "Surprise: 2/2 correct (100.00%)\n",
      "\n",
      "Overall Accuracy: 14/14 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# Dictionary with audio fila paths for SAVEE dataset\n",
    "sav_files = {\n",
    "    \"Neutral\": [\"SAVEE/ALL/JK_n05.wav\", \"SAVEE/ALL/DC_n09.wav\"],\n",
    "    \"Happy\": [\"SAVEE/ALL/JE_h02.wav\", \"SAVEE/ALL/KL_h01.wav\"],\n",
    "    \"Sad\": [\"SAVEE/ALL/DC_sa12.wav\", \"SAVEE/ALL/JK_sa14.wav\"],\n",
    "    \"Angry\": [\"SAVEE/ALL/DC_a04.wav\", \"SAVEE/ALL/KL_a05.wav\"],\n",
    "    \"Fear\": [\"SAVEE/ALL/JK_f11.wav\", \"SAVEE/ALL/JE_f03.wav\"],\n",
    "    \"Disgust\": [\"SAVEE/ALL/DC_d07.wav\", \"SAVEE/ALL/KL_d07.wav\"],\n",
    "    \"Surprise\": [\"SAVEE/ALL/DC_su07.wav\", \"SAVEE/ALL/JK_su03.wav\"]\n",
    "\n",
    "}\n",
    "\n",
    "# Make predictions and evaluate\n",
    "evaluate_predictions(sav_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fffae8-3704-4934-a805-d1ecb769aba4",
   "metadata": {},
   "source": [
    "### Predicting audio files from the TESS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ab9db03d-14e2-4733-bf23-67443894760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral: 2/2 correct (100.00%)\n",
      "Happy: 2/2 correct (100.00%)\n",
      "Sad: 2/2 correct (100.00%)\n",
      "Angry: 2/2 correct (100.00%)\n",
      "Fear: 2/2 correct (100.00%)\n",
      "Disgust: 2/2 correct (100.00%)\n",
      "Surprise: 2/2 correct (100.00%)\n",
      "\n",
      "Overall Accuracy: 14/14 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# Dictionary with audio fila paths for SAVEE dataset\n",
    "tes_files = {\n",
    "    \"Neutral\": [\"TESS/YAF_neutral/YAF_chain_neutral.wav\", \"TESS/OAF_neutral/OAF_have_neutral.wav\"],\n",
    "    \"Happy\": [\"TESS/YAF_happy/YAF_fat_happy.wav\", \"TESS/OAF_happy/OAF_home_happy.wav\"],\n",
    "    \"Sad\": [\"TESS/YAF_sad/YAF_shawl_sad.wav\", \"TESS/OAF_sad/OAF_wire_sad.wav\"],\n",
    "    \"Angry\": [\"TESS/YAF_angry/YAF_judge_angry.wav\", \"TESS/OAF_angry/OAF_pass_angry.wav\"],\n",
    "    \"Fear\": [\"TESS/YAF_fear/YAF_home_fear.wav\", \"TESS/OAF_fear/OAF_choice_fear.wav\"],\n",
    "    \"Disgust\": [\"TESS/YAF_disgust/YAF_ring_disgust.wav\", \"TESS/OAF_disgust/OAF_goal_disgust.wav\"],\n",
    "    \"Surprise\": [\"TESS/YAF_pleasant_surprised/YAF_hurl_ps.wav\", \"TESS/OAF_Pleasant_surprise/OAF_pick_ps.wav\"],\n",
    "\n",
    "}\n",
    "\n",
    "# Make predictions and evaluate\n",
    "evaluate_predictions(tes_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ed793-8d13-4464-8afa-5700ab59771f",
   "metadata": {},
   "source": [
    "### Predicting audio files from the ESD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d150f38c-c460-4d74-8170-05a7d3f1c50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral: 2/2 correct (100.00%)\n",
      "Happy: 2/2 correct (100.00%)\n",
      "Sad: 2/2 correct (100.00%)\n",
      "Angry: 2/2 correct (100.00%)\n",
      "Surprise: 2/2 correct (100.00%)\n",
      "\n",
      "Overall Accuracy: 10/10 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# Dictionary with audio fila paths for SAVEE dataset\n",
    "esd_files = {\n",
    "    \"Neutral\": [\"ESD/0011/Neutral/0011_000103.wav\", \"ESD/0018/Neutral/0018_000055.wav\"],\n",
    "    \"Happy\": [\"ESD/0020/Happy/0020_000756.wav\", \"ESD/0017/Happy/0017_000860.wav\"],\n",
    "    \"Sad\": [\"ESD/0015/Sad/0015_001392.wav\", \"ESD/0017/Sad/0017_001183.wav\"],\n",
    "    \"Angry\": [\"ESD/0017/Angry/0017_000363.wav\", \"ESD/0011/Angry/0011_000645.wav\"],\n",
    "    \"Surprise\": [\"ESD/0013/Surprise/0013_001415.wav\", \"ESD/0020/Surprise/0020_001461.wav\"],\n",
    "\n",
    "}\n",
    "\n",
    "# Make predictions and evaluate\n",
    "evaluate_predictions(esd_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063089f7-790f-4bc6-a708-e5fed1694c80",
   "metadata": {},
   "source": [
    "### Predicting audio files from the MELD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "637d7e09-8f96-4ed0-8506-cb6fea8ae420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral: 2/2 correct (100.00%)\n",
      "Happy: 2/2 correct (100.00%)\n",
      "Sad: 2/2 correct (100.00%)\n",
      "Angry: 2/2 correct (100.00%)\n",
      "Fear: 2/2 correct (100.00%)\n",
      "Disgust: 2/2 correct (100.00%)\n",
      "Surprise: 2/2 correct (100.00%)\n",
      "\n",
      "Overall Accuracy: 14/14 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# Dictionary with audio fila paths for SAVEE dataset\n",
    "mel_files = {\n",
    "    \"Neutral\": [\"MELD/train_splits_audio/dia0_utt1.wav\", \"MELD/train_splits_audio/dia620_utt0.wav\"],\n",
    "    \"Happy\": [\"MELD/train_splits_audio/dia733_utt0.wav\", \"MELD/train_splits_audio/dia33_utt1.wav\"],\n",
    "    \"Sad\": [\"MELD/train_splits_audio/dia82_utt4.wav\", \"MELD/train_splits_audio/dia935_utt4.wav\"],\n",
    "    \"Angry\": [\"MELD/train_splits_audio/dia933_utt11.wav\", \"MELD/train_splits_audio/dia383_utt3.wav\"],\n",
    "    \"Fear\": [\"MELD/train_splits_audio/dia445_utt3.wav\", \"MELD/train_splits_audio/dia120_utt0.wav\"],\n",
    "    \"Disgust\": [\"MELD/train_splits_audio/dia109_utt1.wav\", \"MELD/train_splits_audio/dia1038_utt7.wav\"],\n",
    "    \"Surprise\": [\"MELD/train_splits_audio/dia1038_utt15.wav\", \"MELD/train_splits_audio/dia1019_utt9.wav\"]\n",
    "}\n",
    "\n",
    "# Make predictions and evaluate\n",
    "evaluate_predictions(mel_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33e0d2-426e-4d67-b10e-95fd791d9b00",
   "metadata": {},
   "source": [
    "### Predicting recorded audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "5b3fc37a-c2b8-44f6-ac07-b1171224f8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"recordings/neutral.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "2e87ff9d-4ed3-43c3-bff8-d9032e99adc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"recordings/happy.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "cd1eb2b6-3e32-4ba2-974e-6ab114f12522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sad'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"recordings/sad.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "2c8201f1-b05a-4f32-8951-7bb553e36ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'angry'"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"recordings/angry.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b25bc7ed-10a3-46dd-9593-9ab641bcc6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fear'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"recordings/fear.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "aed5e69e-9d77-45bd-b2f7-e1d44f936a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disgust'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"recordings/disgust.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f5915d2d-d3fe-491c-b198-d3f177646c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'surprise'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"recordings/surprise.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e20e4b-a0b9-429e-8f05-eeebba1f7156",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75828c11-63e3-4ebc-8bab-394bec12ee40",
   "metadata": {},
   "source": [
    "We expect the model to perform really well and give very accurate predictions for all emotions, given the performance of the model. All predictions made are accurate. This means that the model performs extremely well on both seen and unseen real world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c370a-ee76-4ee4-bd3e-873a010338c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow GPU Kernel 2",
   "language": "python",
   "name": "tensor-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
